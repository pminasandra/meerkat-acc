# Pranav Minasandra
# pminasandra.github.io
# Nov 28, 2023
# Yay, happy birthday to me!

"""
Reads the HUGE csv files containing acc info.
"""

import glob
import os.path

import numpy as np
import pandas as pd

import config
import utilities

dtypes_dict_raw = {
    'TagID': str,
    'Timestamp': str,
    'X': np.float64,
    'Y': np.float64,
    'Z': np.float64,
    'Activity': str,
    'location-lat': np.float64,
    'location-lon': np.float64,
    'height-msl': str,
    'ground-speed': np.float64,
    'satellites': str,
    'hdop': str,
    'signal-strength': str,
    'Sensor Raw': str,
    'Battery (V)': str,
    'Metadata': str
}

if not config.SUPPRESS_INFORMATIVE_PRINT:
    old_print = print
    print = utilities.sprint

def validate_acc_file(df, subset_cols=True):
    """
    Checks column labels and behavioral states in a given dataframe
    """
    if subset_cols:
        assert list(df.columns) == ["Timestamp", "X", "Y", "Z"] #labels as generated by tag

def drop_leading_zeros(df):
    """
    Drops the leading zeros of the dfs
    """

# This becomes relevant because the Axy-Treks add a bunch of 0.0s in the data
# before the device turns on

    is_not_all_zeros_mask = ~((df['X']==0.0) & (df['Y']==0.0) & (df['Z']==0.0))
    threshold_index = is_not_all_zeros_mask.idxmax() # finds the first 'True'

    df.drop(df.index[:threshold_index], inplace=True)
    df.reset_index(drop=True, inplace=True)


def load_acc_file(filepath, subset_cols=True):
    csvfilepath = filepath
    if subset_cols:
        csvfile = pd.read_csv(csvfilepath, usecols=["Timestamp", "X", "Y", "Z"])
    else:
        try:
            csvfile = pd.read_csv(csvfilepath, dtype=dtypes_dict_raw)
        except Exception as e:
            print("dtype didn't work, trying again:", e)
            csvfile = pd.read_csv(csvfilepath)
    csvfile['Timestamp'] = pd.to_datetime(csvfile['Timestamp'],
                                format='%d/%m/%Y %H:%M:%S.%f',
                                dayfirst=True)
    validate_acc_file(csvfile, subset_cols=subset_cols)
    drop_leading_zeros(csvfile)

    return csvfile

def load_acc_files(list_of_dplments=config.DEPLOYMENTS, subset_cols=True):
    """
    GENERATOR!!
    Loads and validates dataframes from audit csvs.
    Args:
        list_of_dplments: which deployments to load
        subset_cols: whether to subset to specific cols
    Yields:
        3-tuple: dplment (str), accname (str), and csvfile (pd.DataFrame)
    Raises:
        AssertionError: if there are inappropriate csvfiles
    """
    for dplment in list_of_dplments:
        tgtpath = os.path.join(config.ACC_GPS_DIR, dplment)
        for csvfilepath in glob.glob(os.path.join(tgtpath, "*.csv")):

            csvfile = load_acc_file(csvfilepath)
            yield dplment, os.path.basename(csvfilepath)[:-len(".csv")], csvfile


if __name__ == "__main__":
    accgen = load_acc_files()
    for dplment, name, df in accgen:
        print("\n", dplment, name, "\n", df)
