# Pranav Minasandra
# pminasandra.github.io
# Nov 28, 2023
# Yay, happy birthday to me!

"""
Reads the HUGE csv files containing acc info.
"""

import glob
import os.path

import matplotlib.pyplot as plt
import pandas as pd

import config
import utilities

if not config.SUPPRESS_INFORMATIVE_PRINT:
    old_print = print
    print = utilities.sprint

def validate_acc_file(df):
    """
    Checks column labels and behavioral states in a given dataframe
    """
    assert list(df.columns) == ["Timestamp", "X", "Y", "Z"] #labels as generated by tag

def drop_leading_zeros(df):
    """
    Drops the leading zeros of the dfs
    """

    is_not_all_zeros_mask = ~((df['X']==0.0) & (df['Y']==0.0) & (df['Z']==0.0))
    threshold_index = is_not_all_zeros_mask.idxmax() # finds the first 'True'

    df.drop(df.index[:threshold_index], inplace=True)
    df.reset_index(drop=True, inplace=True)

# This becomes relevant because the Axy-Treks add a bunch of 0.0s in the data
# before the device turns on


def load_acc_files(list_of_dplments=config.DEPLOYMENTS):
    """
    GENERATOR!!
    Loads and validates dataframes from audit csvs.
    Args:
        list_of_dplments: which deployments to load
    Yields:
        3-tuple: dplment (str), auditname (str), and csvfile (pd.DataFrame)
    Raises:
        AssertionError: if there are inappropriate csvfiles
    """
    for dplment in list_of_dplments:
        tgtpath = os.path.join(config.ACC_GPS_DIR, dplment)
        for csvfilepath in glob.glob(os.path.join(tgtpath, "*.csv")):
            csvfile = pd.read_csv(csvfilepath, usecols=["Timestamp", "X", "Y", "Z"])
            csvfile['Timestamp'] = pd.to_datetime(csvfile['Timestamp'], format='%d/%m/%Y %H:%M:%S.%f', dayfirst=True)
            validate_acc_file(csvfile)
            drop_leading_zeros(csvfile)

            yield dplment, os.path.basename(csvfilepath)[:-len(".csv")], csvfile


if __name__ == "__main__":
    auditgen = load_acc_files()
    for dplment, name, df in auditgen:
        print("\n", dplment, name, "\n", df)
